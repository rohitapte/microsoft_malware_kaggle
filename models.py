from sklearn.metrics import roc_auc_score
from features import generate_features_for_ml_algos

train_x,cv_x,train_labels,cv_labels,test_ids,x_test=generate_features_for_ml_algos(encoding_type='categorical')

def run_logistic_regression():
    from sklearn.linear_model import LogisticRegression
    clf=LogisticRegression()
    clf.fit(train_x,train_labels)
    print("Cross validation score %s"%(clf.score(cv_x,cv_labels)))
    predicted_cv=clf.predict_proba(cv_x)
    print("ROC_AUC score %s"%(roc_auc_score(cv_labels,predicted_cv[:,1])))

    predicted=clf.predict_proba(x_test)
    test_ids['HasDetections']=predicted[:,1]
    test_ids[['MachineIdentifier','HasDetections']].to_csv('logistic_regression_one_hot.csv',index=None)

def run_xgboost():
    import xgboost as xgb
    # Set our parameters for xgboost
    eta = 0.1
    max_depth= 10
    subsample = 1
    colsample_bytree = 1
    min_chil_weight=1
    params = {
        "objective": "binary:logistic",
        "booster": "gbtree",
        "eval_metric": "logloss",
        "eta": eta,
        "tree_method": 'exact',
        "max_depth": max_depth,
        "subsample": subsample,
        "colsample_bytree": colsample_bytree,
        "silent": 1,
        "min_chil_weight": min_chil_weight,
        # "num_class" : 22,
    }

    d_train = xgb.DMatrix(train_x, label=train_labels)
    d_valid = xgb.DMatrix(cv_x, label=cv_labels)
    watchlist = [(d_train, 'train'), (d_valid, 'valid')]
    bst = xgb.train(params, d_train, 500, watchlist, early_stopping_rounds=50, verbose_eval=10)
    d_test = xgb.DMatrix(x_test)
    p_test = bst.predict(d_test)
    test_ids['HasDetections'] = p_test
    test_ids[['MachineIdentifier', 'HasDetections']].to_csv('xgboost_onehot.csv', index=None)

#run_logistic_regression()
run_xgboost()